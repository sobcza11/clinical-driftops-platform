name: DriftOps CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Upgrade pip & install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Set MLflow backend (file-based)
        run: echo "MLFLOW_TRACKING_URI=file://$GITHUB_WORKSPACE/mlruns" >> $GITHUB_ENV

      - name: Ensure reports dir
        run: mkdir -p reports

      # ---- Seed predictions for CI (only if none present) ----
      - name: Seed predictions if missing
        if: ${{ always() }}
        run: |
          if [ ! -f reports/predictions.csv ] && [ ! -f reports/predictions_current.csv ] && [ ! -f data/predictions.csv ]; then
            cat << 'CSV' > reports/predictions.csv
y_true,y_score
0,0.10
1,0.90
0,0.20
1,0.80
CSV
          fi

      # ---- Phase V — Performance metrics (AUROC/AUPRC) ----
      # Run early and always, so later failures don't skip it
      - name: Performance metrics
        if: ${{ always() }}
        run: python src/eval/performance_metrics.py

      # -------- Phase III – Data Prep --------
      - name: Data prep (baseline/current)
        run: |
          python src/data_prep.py --scaler standard --outliers zscore
          ls -lah data | sed -n '1,200p'

      # -------- Phase IV – Drift --------
      - name: Drift detector
        run: python src/monitors/drift_detector.py

      # -------- Phase V – SHAP --------
      # (Leave as hard-fail to keep quality high)
      - name: SHAP explainability
        run: |
          python src/explain/shap_summary.py \
            --data data/data_prepared_current.csv \
            --out reports/shap_top_features.png \
            --topk 15

      # -------- Phase V – Fairness (optional) --------
      - name: Fairness audit
        run: python src/eval/fairness_audit.py
        continue-on-error: true

      # -------- Phase V – Trustworthy Audit (optional) --------
      - name: Build trustworthy audit
        run: python src/eval/make_trustworthy_audit.py
        continue-on-error: true

      # -------- Phase VI – Policy Gate (hard fail on violation) --------
      - name: Enforce policy gate
        run: python src/ops/policy_gate.py

      # Always upload the gate JSON so we can inspect failures
      - name: Upload policy gate result
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: policy_gate_result
          path: reports/policy_gate_result.json
          if-no-files-found: warn

      # Build dashboard (always)
      - name: Build dashboard
        if: ${{ always() }}
        run: python src/reports_dashboard.py

      # Collect artifacts even if earlier steps failed
      - name: Upload artifacts (zip)
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: driftops-reports
          path: |
            reports/**
            mlruns/**
            policy.yaml
          if-no-files-found: warn
          retention-days: 30

      # Prepare Pages artifact (publishes /reports)
      - name: Upload Pages artifact
        if: ${{ always() }}
        uses: actions/upload-pages-artifact@v3
        with:
          path: reports

  deploy:
    if: ${{ always() }}
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

      - name: Echo site URL
        run: echo "PAGES_URL=${{ steps.deployment.outputs.page_url }}"
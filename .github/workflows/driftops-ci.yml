name: DriftOps CI

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  build:
    name: Build reports & upload
    runs-on: ubuntu-latest

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Install deps
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Configure MLflow (file-based)
        run: echo "MLFLOW_TRACKING_URI=file://$GITHUB_WORKSPACE/mlruns" >> $GITHUB_ENV

      - name: Ensure reports dir
        run: mkdir -p reports

      # Seed tiny predictions if none present (no heredoc; safe YAML)
      - name: Seed predictions if missing
        run: |
          if [ ! -f reports/predictions.csv ] && [ ! -f reports/predictions_current.csv ] && [ ! -f data/predictions.csv ]; then
            printf "y_true,y_score\n0,0.10\n1,0.90\n0,0.20\n1,0.80\n" > reports/predictions.csv
          fi

      # Phase V — Performance metrics (run early and always)
      - name: Performance metrics
        if: ${{ always() }}
        run: python src/eval/performance_metrics.py

      # Phase III — Data prep
      - name: Data prep
        run: |
          python src/data_prep.py --scaler standard --outliers zscore
          ls -lah data | sed -n '1,200p'

      # Phase IV — Drift
      - name: Drift detector
        run: python src/monitors/drift_detector.py

      # Phase V — SHAP
      - name: SHAP explainability
        run: |
          python src/explain/shap_summary.py \
            --data data/data_prepared_current.csv \
            --out reports/shap_top_features.png \
            --topk 15

      # Phase V — Fairness (optional)
      - name: Fairness audit
        run: python src/eval/fairness_audit.py
        continue-on-error: true

      # Phase V — Trustworthy Audit (optional)
      - name: Build trustworthy audit
        run: python src/eval/make_trustworthy_audit.py
        continue-on-error: true

      # Phase VI — Policy gate (hard fail if violated)
      - name: Enforce policy gate
        run: python src/ops/policy_gate.py

      # Always build dashboard & upload artifacts
      - name: Build dashboard
        if: ${{ always() }}
        run: python src/reports_dashboard.py

      - name: Upload artifacts (zip)
        if: ${{ always() }}
        uses: actions/upload-artifact@v4
        with:
          name: driftops-reports
          path: |
            reports/**
            mlruns/**
            policy.yaml
          if-no-files-found: warn
          retention-days: 30

      # Pages artifact (publishes ./reports)
      - name: Upload Pages artifact
        if: ${{ always() }}
        uses: actions/upload-pages-artifact@v3
        with:
          path: reports

  deploy:
    if: ${{ always() }}
    needs: build
    runs-on: ubuntu-latest
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

      - name: Echo Pages URL
        run: echo "PAGES_URL=${{ steps.deployment.outputs.page_url }}"